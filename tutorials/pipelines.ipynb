{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marovi Pipeline Framework Demo\n",
    "\n",
    "This notebook demonstrates the power of combining the Marovi Pipeline Framework with MaroviAPI client services for document processing workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary components from the Marovi framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core pipeline components\n",
    "from marovi.pipelines.core import PipelineStep, Pipeline\n",
    "from marovi.pipelines.context import PipelineContext\n",
    "from typing import List\n",
    "\n",
    "# Import API client and schemas\n",
    "from marovi.api.core.client import MaroviAPI\n",
    "from marovi.api.custom.schemas import FormatConversionRequest, SummarizationRequest\n",
    "\n",
    "# Import MaroviAPI steps\n",
    "from marovi.modules.steps.marovi_api import TranslateStep\n",
    "\n",
    "import logging\n",
    "\n",
    "# Configure logging to reduce verbosity\n",
    "logging.basicConfig(level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Pipeline Example\n",
    "\n",
    "Let's start with a simple pipeline that capitalizes text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-11 22:28:58 - marovi.pipelines.core - INFO - Initialized capitalize_pipeline pipeline with 1 steps\n",
      "2025-05-11 22:28:58 - marovi.pipelines.context - INFO - Initialized PipelineContext ctx_1747027738_10c65f340 with metadata: {'description': 'Basic capitalization demo'}\n",
      "2025-05-11 22:28:58 - marovi.pipelines.core - INFO - Running step 'capitalize' (1/1) with 3 inputs\n",
      "2025-05-11 22:28:58 - marovi.pipelines.core - INFO - capitalize: Successfully processed 1 items in 0.00s\n",
      "2025-05-11 22:28:58 - marovi.pipelines.core - INFO - capitalize: Successfully processed 1 items in 0.00s\n",
      "2025-05-11 22:28:58 - marovi.pipelines.core - INFO - capitalize: Successfully processed 1 items in 0.00s\n",
      "2025-05-11 22:28:58 - marovi.pipelines.context - INFO - Saved checkpoint to checkpoints/ctx_1747027738_10c65f340_capitalize_pipeline_after_capitalize.json\n",
      "2025-05-11 22:28:58 - marovi.pipelines.core - INFO - Checkpoint saved: checkpoints/ctx_1747027738_10c65f340_capitalize_pipeline_after_capitalize.json\n",
      "2025-05-11 22:28:58 - marovi.pipelines.core - INFO - Completed step 'capitalize' with 3 outputs\n",
      "2025-05-11 22:28:58 - marovi.pipelines.core - INFO - Pipeline 'capitalize_pipeline' completed successfully in 0.00s\n",
      "Pipeline results:\n",
      "  [0]: HELLO, WORLD!\n",
      "  [1]: THIS IS A TEST.\n",
      "  [2]: PIPELINES ARE FUN!\n",
      "\n",
      "Execution metrics:\n",
      "  Total execution time: 0.0024 seconds\n",
      "  Steps executed: 1\n"
     ]
    }
   ],
   "source": [
    "# Create a list of input strings\n",
    "input_strings = [\n",
    "    \"Hello, world!\",\n",
    "    \"This is a test.\",\n",
    "    \"Pipelines are fun!\"\n",
    "]\n",
    "\n",
    "# Define a simple step that capitalizes all strings\n",
    "class CapitalizeStep(PipelineStep[str, str]):\n",
    "    def process(self, inputs: List[str], context: PipelineContext) -> List[str]:\n",
    "        return [text.upper() for text in inputs]\n",
    "\n",
    "# Create a pipeline with a single step that capitalizes all strings\n",
    "capitalize_step = CapitalizeStep(step_id=\"capitalize\")\n",
    "pipeline = Pipeline(steps=[capitalize_step], name=\"capitalize_pipeline\")\n",
    "\n",
    "# Create a pipeline context\n",
    "context = PipelineContext(metadata={\"description\": \"Basic capitalization demo\"})\n",
    "\n",
    "# Run the pipeline\n",
    "results = pipeline.run(input_strings, context)\n",
    "\n",
    "# Print the results\n",
    "print(\"Pipeline results:\")\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"  [{i}]: {result}\")\n",
    "\n",
    "# Access execution data from the context\n",
    "print(\"\\nExecution metrics:\")\n",
    "print(f\"  Total execution time: {context.get_metric('pipeline_total_execution_time'):.4f} seconds\")\n",
    "print(f\"  Steps executed: {context.get_metric('pipeline_steps_executed')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Paper Processing Pipeline\n",
    "\n",
    "Now let's create a more complex pipeline that processes research papers through multiple stages:\n",
    "\n",
    "1. Convert HTML to Markdown\n",
    "2. Summarize the content\n",
    "3. Translate to Spanish\n",
    "4. Convert back to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 sample research papers\n"
     ]
    }
   ],
   "source": [
    "# Sample research paper HTML content\n",
    "research_papers = [\n",
    "    # Paper 1: Machine Learning\n",
    "    \"\"\"<article>\n",
    "      <h1>Advances in Deep Reinforcement Learning</h1>\n",
    "      <div class=\"abstract\">\n",
    "        <h2>Abstract</h2>\n",
    "        <p>Deep reinforcement learning has emerged as a powerful technique for solving complex decision-making problems. This paper presents a novel approach that combines hierarchical learning with transformer architectures to improve sample efficiency and generalization. Our method demonstrates state-of-the-art performance on benchmark environments while requiring 40% fewer training samples.</p>\n",
    "      </div>\n",
    "    </article>\"\"\",\n",
    "    \n",
    "    # Paper 2: Natural Language Processing\n",
    "    \"\"\"<article>\n",
    "      <h1>Efficient Fine-tuning Methods for Large Language Models</h1>\n",
    "      <div class=\"abstract\">\n",
    "        <h2>Abstract</h2>\n",
    "        <p>As large language models grow in size, efficient fine-tuning becomes increasingly important. We investigate parameter-efficient techniques including LoRA, prefix tuning, and prompt tuning. Our experiments show that these methods can achieve comparable performance to full fine-tuning while updating less than 1% of the parameters, significantly reducing computational requirements and carbon footprint.</p>\n",
    "      </div>\n",
    "    </article>\"\"\"\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(research_papers)} sample research papers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Pipeline Steps\n",
    "\n",
    "Let's create custom steps for each stage of our document processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HTMLToMarkdownStep(PipelineStep[str, str]):\n",
    "    \"\"\"Converts HTML to Markdown using the MaroviAPI.\"\"\"\n",
    "    \n",
    "    def __init__(self, step_id: str = \"html_to_markdown\"):\n",
    "        super().__init__(step_id=step_id)\n",
    "        self.client = MaroviAPI()\n",
    "    \n",
    "    def process(self, inputs: List[str], context: PipelineContext) -> List[str]:\n",
    "        results = []\n",
    "        for html in inputs:\n",
    "            # Create request object\n",
    "            request = FormatConversionRequest(\n",
    "                text=html,\n",
    "                source_format=\"html\",\n",
    "                target_format=\"markdown\",\n",
    "                preserve_structure=True,\n",
    "                preserve_links=True\n",
    "            )\n",
    "            \n",
    "            # Call the API directly\n",
    "            response = self.client.custom.convert_format(request)\n",
    "            \n",
    "            # Extract converted text\n",
    "            results.append(response.converted_text)\n",
    "        \n",
    "        return results\n",
    "\n",
    "class SummarizeTextStep(PipelineStep[str, str]):\n",
    "    \"\"\"Summarizes text using the MaroviAPI.\"\"\"\n",
    "    \n",
    "    def __init__(self, style: str = \"paragraph\", max_length: int = 100, step_id: str = \"summarize\"):\n",
    "        super().__init__(step_id=step_id)\n",
    "        self.client = MaroviAPI()\n",
    "        self.style = style\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def process(self, inputs: List[str], context: PipelineContext) -> List[str]:\n",
    "        results = []\n",
    "        for text in inputs:\n",
    "            # Create request object\n",
    "            request = SummarizationRequest(\n",
    "                text=text,\n",
    "                style=self.style,\n",
    "                max_length=self.max_length\n",
    "            )\n",
    "            \n",
    "            # Call the API directly\n",
    "            response = self.client.custom.summarize(request)\n",
    "            \n",
    "            # Extract summary text\n",
    "            results.append(response.summary)\n",
    "        \n",
    "        return results\n",
    "\n",
    "class MarkdownToHTMLStep(PipelineStep[str, str]):\n",
    "    \"\"\"Converts Markdown to HTML using the MaroviAPI.\"\"\"\n",
    "    \n",
    "    def __init__(self, step_id: str = \"markdown_to_html\"):\n",
    "        super().__init__(step_id=step_id)\n",
    "        self.client = MaroviAPI()\n",
    "    \n",
    "    def process(self, inputs: List[str], context: PipelineContext) -> List[str]:\n",
    "        results = []\n",
    "        for markdown in inputs:\n",
    "            # Create request object\n",
    "            request = FormatConversionRequest(\n",
    "                text=markdown,\n",
    "                source_format=\"markdown\",\n",
    "                target_format=\"html\",\n",
    "                preserve_structure=True,\n",
    "                preserve_links=True\n",
    "            )\n",
    "            \n",
    "            # Call the API directly\n",
    "            response = self.client.custom.convert_format(request)\n",
    "            \n",
    "            # Extract converted text\n",
    "            results.append(response.converted_text)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and Running the Pipeline\n",
    "\n",
    "Now let's assemble the pipeline and run it on our research papers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-11 22:28:58 - marovi.api.clients.translation - INFO - Initialized TranslationClient with provider=google\n",
      "2025-05-11 22:28:59 - marovi.modules.steps.marovi_api - INFO - Initialized translate_en_to_es with endpoint translation.translate\n",
      "2025-05-11 22:28:59 - marovi.pipelines.core - INFO - Initialized research_paper_pipeline pipeline with 4 steps\n",
      "Pipeline created with 4 steps\n"
     ]
    }
   ],
   "source": [
    "# Create the step instances\n",
    "html_to_markdown_step = HTMLToMarkdownStep()\n",
    "summarize_step = SummarizeTextStep(style=\"paragraph\", max_length=100)\n",
    "translate_step = TranslateStep(source_lang=\"en\", target_lang=\"es\", provider=\"google\")\n",
    "markdown_to_html_step = MarkdownToHTMLStep()\n",
    "\n",
    "# Create the pipeline\n",
    "research_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        html_to_markdown_step,\n",
    "        summarize_step,\n",
    "        translate_step,\n",
    "        markdown_to_html_step\n",
    "    ],\n",
    "    name=\"research_paper_pipeline\"\n",
    ")\n",
    "\n",
    "print(\"Pipeline created with 4 steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-11 22:28:59 - marovi.pipelines.context - INFO - Initialized PipelineContext ctx_1747027739_10cac4c70 with metadata: {'description': 'Research paper processing pipeline', 'version': '1.0', 'paper_count': 2}\n",
      "Starting pipeline execution...\n",
      "2025-05-11 22:28:59 - marovi.pipelines.core - INFO - Running step 'html_to_markdown' (1/4) with 2 inputs\n",
      "2025-05-11 22:28:59 - marovi.api.clients.custom - INFO - Initialized CustomClient for endpoint=convert_format\n",
      "2025-05-11 22:28:59 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-11 22:28:59 - marovi.pipelines.core - INFO - html_to_markdown: Successfully processed 1 items in 0.93s\n",
      "2025-05-11 22:29:00 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-11 22:29:00 - marovi.pipelines.core - INFO - html_to_markdown: Successfully processed 1 items in 0.83s\n",
      "2025-05-11 22:29:00 - marovi.pipelines.context - INFO - Saved checkpoint to checkpoints/ctx_1747027739_10cac4c70_research_paper_pipeline_after_html_to_markdown.json\n",
      "2025-05-11 22:29:00 - marovi.pipelines.core - INFO - Checkpoint saved: checkpoints/ctx_1747027739_10cac4c70_research_paper_pipeline_after_html_to_markdown.json\n",
      "2025-05-11 22:29:00 - marovi.pipelines.core - INFO - Completed step 'html_to_markdown' with 2 outputs\n",
      "2025-05-11 22:29:00 - marovi.pipelines.core - INFO - Running step 'summarize' (2/4) with 2 inputs\n",
      "2025-05-11 22:29:00 - marovi.api.clients.custom - INFO - Initialized CustomClient for endpoint=summarize\n",
      "2025-05-11 22:29:00 - marovi.api.custom.endpoints.summarize - INFO - Summarizing text with style: paragraph\n",
      "2025-05-11 22:29:02 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-11 22:29:02 - marovi.api.custom.endpoints.summarize - INFO - Successfully summarized text: 57 words → 95 words\n",
      "2025-05-11 22:29:02 - marovi.pipelines.core - INFO - summarize: Successfully processed 1 items in 1.73s\n",
      "2025-05-11 22:29:02 - marovi.api.custom.endpoints.summarize - INFO - Summarizing text with style: paragraph\n",
      "2025-05-11 22:29:07 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-11 22:29:07 - marovi.api.custom.endpoints.summarize - INFO - Successfully summarized text: 63 words → 77 words\n",
      "2025-05-11 22:29:07 - marovi.pipelines.core - INFO - summarize: Successfully processed 1 items in 5.03s\n",
      "2025-05-11 22:29:07 - marovi.pipelines.context - INFO - Saved checkpoint to checkpoints/ctx_1747027739_10cac4c70_research_paper_pipeline_after_summarize.json\n",
      "2025-05-11 22:29:07 - marovi.pipelines.core - INFO - Checkpoint saved: checkpoints/ctx_1747027739_10cac4c70_research_paper_pipeline_after_summarize.json\n",
      "2025-05-11 22:29:07 - marovi.pipelines.core - INFO - Completed step 'summarize' with 2 outputs\n",
      "2025-05-11 22:29:07 - marovi.pipelines.core - INFO - Running step 'translate_en_to_es' (3/4) with 2 inputs\n",
      "2025-05-11 22:29:07 - marovi.modules.steps.marovi_api - INFO - translate_en_to_es: Processing 1 items individually\n",
      "2025-05-11 22:29:07 - marovi.modules.steps.marovi_api - INFO - translate_en_to_es: Processing 1 items individually\n",
      "2025-05-11 22:29:07 - marovi.api.clients.translation - INFO - Translation successful: google, source=en, target=es, latency: 0.27s\n",
      "2025-05-11 22:29:07 - marovi.api.clients.translation - INFO - Translation successful: google, source=en, target=es, latency: 0.27s\n",
      "2025-05-11 22:29:07 - marovi.pipelines.core - INFO - translate_en_to_es: Successfully processed 2 items in 0.27s\n",
      "2025-05-11 22:29:07 - marovi.pipelines.context - INFO - Saved checkpoint to checkpoints/ctx_1747027739_10cac4c70_research_paper_pipeline_after_translate_en_to_es.json\n",
      "2025-05-11 22:29:07 - marovi.pipelines.core - INFO - Checkpoint saved: checkpoints/ctx_1747027739_10cac4c70_research_paper_pipeline_after_translate_en_to_es.json\n",
      "2025-05-11 22:29:07 - marovi.pipelines.core - INFO - Completed step 'translate_en_to_es' with 2 outputs\n",
      "2025-05-11 22:29:07 - marovi.pipelines.core - INFO - Running step 'markdown_to_html' (4/4) with 2 inputs\n",
      "2025-05-11 22:29:07 - marovi.api.clients.custom - INFO - Initialized CustomClient for endpoint=convert_format\n",
      "2025-05-11 22:29:09 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-11 22:29:09 - marovi.pipelines.core - INFO - markdown_to_html: Successfully processed 1 items in 1.81s\n",
      "2025-05-11 22:29:11 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-05-11 22:29:11 - marovi.pipelines.core - INFO - markdown_to_html: Successfully processed 1 items in 1.50s\n",
      "2025-05-11 22:29:11 - marovi.pipelines.context - INFO - Saved checkpoint to checkpoints/ctx_1747027739_10cac4c70_research_paper_pipeline_after_markdown_to_html.json\n",
      "2025-05-11 22:29:11 - marovi.pipelines.core - INFO - Checkpoint saved: checkpoints/ctx_1747027739_10cac4c70_research_paper_pipeline_after_markdown_to_html.json\n",
      "2025-05-11 22:29:11 - marovi.pipelines.core - INFO - Completed step 'markdown_to_html' with 2 outputs\n",
      "2025-05-11 22:29:11 - marovi.pipelines.core - INFO - Pipeline 'research_paper_pipeline' completed successfully in 12.11s\n",
      "Pipeline execution completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a context for our pipeline run\n",
    "paper_context = PipelineContext(\n",
    "    metadata={\n",
    "        \"description\": \"Research paper processing pipeline\",\n",
    "        \"version\": \"1.0\",\n",
    "        \"paper_count\": len(research_papers)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Run the pipeline\n",
    "try:\n",
    "    print(\"Starting pipeline execution...\")\n",
    "    final_outputs = research_pipeline.run(research_papers, paper_context)\n",
    "    print(\"Pipeline execution completed successfully!\")\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"Pipeline execution failed: {str(e)}\")\n",
    "    traceback.print_exc()\n",
    "    print(\"Note: This example requires the MaroviAPI client to be configured with valid API credentials.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining Results and Metrics\n",
    "\n",
    "Let's examine the intermediate and final results, as well as performance metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== INTERMEDIATE RESULTS =====\n",
      "\n",
      "----- MARKDOWN FORMAT (Sample) -----\n",
      "```markdown\n",
      "# Efficient Fine-tuning Methods for Large Language Models\n",
      "\n",
      "## Abstract\n",
      "\n",
      "As large language models grow in size, efficient fine-tuning becomes increasingly important. We investigate parameter-efficient techniques including LoRA, prefix tuning, and prompt tuning. Our experiments show that t...\n",
      "\n",
      "----- SUMMARY (Sample) -----\n",
      "The text discusses the importance of efficient fine-tuning methods for large language models as their size increases. It explores parameter-efficient techniques such as LoRA, prefix tuning, and prompt tuning. The findings from the experiments indicate that these methods can achieve performance levels comparable to full fine-tuning while updating less than 1% of the model's parameters. This approach significantly reduces computational demands and the associated carbon footprint, highlighting the potential for more sustainable and resource-efficient model training practices.\n",
      "\n",
      "----- SPANISH TRANSLATION (Sample) -----\n",
      "El artículo analiza los avances en el aprendizaje por refuerzo profundo, destacando un enfoque novedoso que integra el aprendizaje jerárquico con arquitecturas de transformador. Este método busca mejorar la eficiencia y la generalización de las muestras en la resolución de problemas complejos de toma de decisiones. La técnica propuesta alcanza un rendimiento de vanguardia en entornos de referencia, a la vez que reduce significativamente el número de muestras de entrenamiento requeridas en un 40 %. Esta mejora subraya el potencial de combinar estructuras jerárquicas con arquitecturas avanzadas de redes neuronales para optimizar los procesos de aprendizaje en tareas de aprendizaje por refuerzo. Los hallazgos sugieren una dirección prometedora para futuras investigaciones en la mejora de la eficiencia y la eficacia de los modelos de aprendizaje por refuerzo profundo.\n"
     ]
    }
   ],
   "source": [
    "# Show intermediate results\n",
    "print(\"\\n===== INTERMEDIATE RESULTS =====\")\n",
    "\n",
    "# Get results after HTML to Markdown conversion\n",
    "markdown_results = paper_context.get_outputs(\"html_to_markdown\")\n",
    "if markdown_results and len(markdown_results) > 0:\n",
    "    print(\"\\n----- MARKDOWN FORMAT (Sample) -----\")\n",
    "    print(markdown_results[0][:300] + \"...\" if len(markdown_results[0]) > 300 else markdown_results[0])\n",
    "else:\n",
    "    print(\"\\n----- MARKDOWN FORMAT (Sample) -----\")\n",
    "    print(\"No markdown results available\")\n",
    "\n",
    "# Get results after summarization\n",
    "summary_results = paper_context.get_outputs(\"summarize\")\n",
    "if summary_results and len(summary_results) > 0:\n",
    "    print(\"\\n----- SUMMARY (Sample) -----\")\n",
    "    print(summary_results[0])\n",
    "else:\n",
    "    print(\"\\n----- SUMMARY (Sample) -----\")\n",
    "    print(\"No summary results available\")\n",
    "\n",
    "# Get results after translation\n",
    "translation_results = paper_context.get_outputs(\"translate_en_to_es\")\n",
    "if translation_results and len(translation_results) > 0:\n",
    "    print(\"\\n----- SPANISH TRANSLATION (Sample) -----\")\n",
    "    print(translation_results[0])\n",
    "else:\n",
    "    print(\"\\n----- SPANISH TRANSLATION (Sample) -----\")\n",
    "    print(\"No translation results available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- FINAL HTML (Sample) -----\n",
      "```html\n",
      "<p>El artículo analiza los avances en el aprendizaje por refuerzo profundo, destacando un enfoque novedoso que integra el aprendizaje jerárquico con arquitecturas de transformador. Este método busca mejorar la eficiencia y la generalización de las muestras en la resolución de problemas compl...\n"
     ]
    }
   ],
   "source": [
    "# Final HTML results\n",
    "if final_outputs and len(final_outputs) > 0:\n",
    "    print(\"\\n----- FINAL HTML (Sample) -----\")\n",
    "    print(final_outputs[0][:300] + \"...\" if len(final_outputs[0]) > 300 else final_outputs[0])\n",
    "else:\n",
    "    print(\"\\n----- FINAL HTML (Sample) -----\")\n",
    "    print(\"No final HTML results available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== PIPELINE METRICS =====\n",
      "Total execution time: 12.11 seconds\n",
      "\n",
      "Step execution times:\n",
      "  HTML to Markdown: 1.76 seconds\n",
      "  Summarization: 6.76 seconds\n",
      "  Translation: 0.27 seconds\n",
      "  Markdown to HTML: 3.31 seconds\n"
     ]
    }
   ],
   "source": [
    "# Pipeline metrics\n",
    "print(\"\\n===== PIPELINE METRICS =====\")\n",
    "print(f\"Total execution time: {paper_context.get_metric('pipeline_total_execution_time'):.2f} seconds\")\n",
    "\n",
    "# Individual step metrics\n",
    "print(\"\\nStep execution times:\")\n",
    "html_md_time = paper_context.get_metric('step_html_to_markdown_execution_time')\n",
    "summarize_time = paper_context.get_metric('step_summarize_execution_time')\n",
    "translate_time = paper_context.get_metric('step_translate_en_to_es_execution_time')\n",
    "md_html_time = paper_context.get_metric('step_markdown_to_html_execution_time')\n",
    "\n",
    "print(f\"  HTML to Markdown: {html_md_time:.2f} seconds\" if html_md_time is not None else \"  HTML to Markdown: No time recorded\")\n",
    "print(f\"  Summarization: {summarize_time:.2f} seconds\" if summarize_time is not None else \"  Summarization: No time recorded\")\n",
    "print(f\"  Translation: {translate_time:.2f} seconds\" if translate_time is not None else \"  Translation: No time recorded\")\n",
    "print(f\"  Markdown to HTML: {md_html_time:.2f} seconds\" if md_html_time is not None else \"  Markdown to HTML: No time recorded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits of the Pipeline Framework\n",
    "\n",
    "This example demonstrates several key advantages of using the Marovi Pipeline Framework:\n",
    "\n",
    "1. **Modularity**: Each step is self-contained and can be tested/developed independently\n",
    "2. **Type Safety**: Strong typing ensures data consistency through the pipeline\n",
    "3. **Checkpointing**: Results are automatically saved after each step\n",
    "4. **Observability**: Comprehensive metrics tracking\n",
    "5. **Reusability**: Pipeline components can be reconfigured for different workflows\n",
    "6. **Error Handling**: Robust retry mechanisms and error reporting\n",
    "\n",
    "By combining MaroviAPI services with the Pipeline Framework, we can create powerful document processing workflows with minimal code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
